# AUTOGENERATED! DO NOT EDIT! File to edit: ../digit_torch.ipynb.

# %% auto 0
__all__ = ['image_size', 'composed', 'train_dataset', 'test_dataset', 'input_shape', 'learning_rate', 'train_accuracy_list',
           'test_accuracy_list', 'loss_list', 'batch_size', 'test_batch_size', 'epochs', 'model', 'criterion',
           'optimizer', 'train_loader', 'test_loader', 'loss', 'accuracy', 'CNN']

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
# %% ../digit_torch.ipynb 1
# Import relevant libraries
import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from PIL import Image

# %% ../digit_torch.ipynb 2
# Get the relevant dataset and do the required preprocessing

image_size = 28

composed = transforms.Compose([
    transforms.Resize(size=(image_size, image_size)),
    transforms.RandomAffine(degrees=45, shear=1),
    transforms.ToTensor()
])

train_dataset = dsets.MNIST(
    root='./data', download=True, train=True, transform=composed)
test_dataset = dsets.MNIST(
    root='./data', download=True, train=False, transform=composed)

# %% ../digit_torch.ipynb 3
# Define the convolutional model


class CNN(nn.Module):

    def __init__(self, num_filters1, num_filters2):
        super(CNN, self).__init__()
        self.cnn1 = nn.Conv2d(
            in_channels=1, out_channels=num_filters1, kernel_size=3, stride=1, padding='same')
        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.cnn2 = nn.Conv2d(
            in_channels=num_filters1, out_channels=num_filters2, kernel_size=3, stride=1, padding='same')
        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(49*num_filters2, 256)
        self.fc2 = nn.Linear(256, 64)
        self.fc3 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.cnn1(x)
        x = torch.relu(x)
        x = self.maxpool1(x)
        x = self.cnn2(x)
        x = torch.relu(x)
        x = self.maxpool2(x)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = torch.relu(x)
        x = self.fc2(x)
        x = torch.relu(x)
        x = self.fc3(x)
        return x

# %% ../digit_torch.ipynb 4
# Define the parameters


input_shape = (28, 28, 1)
learning_rate = 1e-1
train_accuracy_list = []
test_accuracy_list = []
loss_list = []
batch_size = 256
test_batch_size = 6000
epochs = 10

# Define the model

model = CNN(16, 32)

# Define the loss function
criterion = nn.CrossEntropyLoss()

# Define the optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

# %% ../digit_torch.ipynb 5
# Define the dataloaders

train_loader = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size)
test_loader = torch.utils.data.DataLoader(
    test_dataset, batch_size=test_batch_size)

# Train the model

loss = 0
accuracy = 0

for epoch in range(epochs):
    correct_train = 0
    loss = 0
    for x, y in train_loader:
        optimizer.zero_grad()
        y_pred = model(x)
        loss_val = criterion(y_pred, y)
        loss_val.backward()
        optimizer.step()
        loss += loss_val
        _, yhat = torch.max(y_pred.data, 1)
        correct_train += (yhat == y).sum().item()
    accuracy = correct_train / len(test_dataset)
    train_accuracy_list.append(accuracy)
    loss_list.append(loss.data)
    correct_test = 0
    for x, y in test_loader:
        y_pred = model(x)
        _, yhat = torch.max(y_pred.data, 1)
        correct_test += (yhat == y).sum().item()
    accuracy = correct_test / len(test_dataset)
    test_accuracy_list.append(accuracy)
    print(f"Loss: {loss}, Accuracy: {accuracy}")

# %% ../digit_torch.ipynb 6
# Plot the loss and accuracy
plt.plot(train_accuracy_list, label='Training Accuracy')
plt.plot(test_accuracy_list, label='Test Accuracy')
plt.plot(loss_list, label='Loss')
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.legend()
plt.show()
