{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "908b5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp digit_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "66b8bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Import relevant libraries\n",
    "import tensorflow as tf\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5d977a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Get the relevant dataset and do the required preprocessing\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train).astype('float32')\n",
    "y_test = tf.keras.utils.to_categorical(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf6efd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Define the convolutional model\n",
    "\n",
    "\n",
    "class cnn(tf.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(cnn, self).__init__()\n",
    "        self.W_cnn1 = tf.Variable(tf.random.normal([3, 3, 1, 16], stddev=0.1),\n",
    "                                  name=\"w_cnn1\")\n",
    "        self.b_cnn1 = tf.Variable(tf.constant(0.1, shape=[16]), name=\"b_cnn2\")\n",
    "        self.W_cnn2 = tf.Variable(tf.random.normal([3, 3, 16, 32], stddev=0.1),\n",
    "                                  name=\"w_cnn2\")\n",
    "        self.b_cnn2 = tf.Variable(tf.constant(0.1, shape=[32]), name=\"b_cnn2\")\n",
    "        self.w1 = tf.Variable(tf.random.normal([1568, 256], stddev=0.1),\n",
    "                              name=\"w1\")\n",
    "        self.b1 = tf.Variable(tf.random.normal([1, 256], stddev=0.1),\n",
    "                              name=\"b1\")\n",
    "        self.w2 = tf.Variable(tf.random.normal([256, 64], stddev=0.1),\n",
    "                              name=\"w2\")\n",
    "        self.b2 = tf.Variable(tf.random.normal([1, 64], stddev=0.1), name=\"b2\")\n",
    "        self.w3 = tf.Variable(tf.random.normal([64, 10], stddev=0.1),\n",
    "                              name=\"w3\")\n",
    "        self.b3 = tf.Variable(tf.random.normal([1, 10], stddev=0.1), name=\"b3\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.nn.conv2d(\n",
    "            x, filters=self.W_cnn1, padding='SAME', strides=[1, 1, 1, 1\n",
    "                                                             ]) + self.b_cnn1\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=(2, 2), strides=(2, 2), padding=\"VALID\")\n",
    "        x = tf.nn.conv2d(\n",
    "            x, filters=self.W_cnn2, padding='SAME', strides=[1, 1, 1, 1\n",
    "                                                             ]) + self.b_cnn2\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool2d(x, ksize=(2, 2), strides=(2, 2), padding=\"VALID\")\n",
    "        x = tf.reshape(x, [-1, 1568])\n",
    "        x = tf.matmul(x, self.w1) + self.b1\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.matmul(x, self.w2) + self.b2\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.matmul(x, self.w3) + self.b3\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7fc2c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Define the parameters\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = y_train.shape[1]\n",
    "learning_rate = 1e-3\n",
    "accuracy_list = []\n",
    "loss_list = []\n",
    "batch_size = 256\n",
    "test_batch_size = 6000\n",
    "epochs = 10\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_train, y_train)).batch(batch_size)\n",
    "test_loader = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_test, y_test)).batch(test_batch_size)\n",
    "\n",
    "#Define the loss function\n",
    "lossfunc = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "def cross_entropy(y_label, y_pred):\n",
    "    return (-tf.reduce_sum(y_label * tf.math.log(y_pred + 1.e-10)))\n",
    "\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "17e970f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2267.22314453125, Accuracy: 0.0\n",
      "Loss: 2320.705810546875, Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     20\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m lossfunc(y, y_pred)\n\u001b[1;32m---> 21\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(variables):\n\u001b[0;32m     23\u001b[0m     item\u001b[38;5;241m.\u001b[39massign_sub(learning_rate \u001b[38;5;241m*\u001b[39m grads[index])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1112\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1106\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1107\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1108\u001b[0m           output_gradients))\n\u001b[0;32m   1109\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1110\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1112\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1121\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:581\u001b[0m, in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    572\u001b[0m shape_0, shape_1 \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape_n([op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;66;03m# in Eager mode.\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 581\u001b[0m     \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_backprop_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    591\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d_backprop_filter(\n\u001b[0;32m    592\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    593\u001b[0m         shape_1,\n\u001b[0;32m    594\u001b[0m         grad,\n\u001b[0;32m    595\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[0;32m    596\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[0;32m    597\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    598\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[0;32m    599\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[0;32m    600\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format)\n\u001b[0;32m    601\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1545\u001b[0m, in \u001b[0;36mconv2d_backprop_input\u001b[1;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   1544\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1545\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv2DBackpropInput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_backprop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_cudnn_on_gpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpadding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplicit_paddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdilations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   1551\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#|export\n",
    "#Fit the model\n",
    "\n",
    "loss = 0\n",
    "accuracy = 0\n",
    "\n",
    "model = cnn(input_shape, num_classes)\n",
    "\n",
    "variables = [\n",
    "    model.W_cnn1, model.b_cnn1, model.W_cnn2, model.b_cnn2, model.w1, model.b1,\n",
    "    model.w2, model.b2, model.w3, model.b3\n",
    "]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for batch in train_loader:\n",
    "        (x, y) = batch\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x)\n",
    "            loss_val = lossfunc(y, y_pred)\n",
    "            grads = tape.gradient(loss_val, variables)\n",
    "            for index, item in enumerate(variables):\n",
    "                item.assign_sub(learning_rate * grads[index])\n",
    "            loss += loss_val\n",
    "    loss_list.append(loss)\n",
    "    correct_pred = 0\n",
    "    for batch in test_loader:\n",
    "        (x, y) = batch\n",
    "        y = tf.argmax(y).numpy()\n",
    "        y_pred = tf.argmax(tf.nn.softmax(model(x))).numpy()\n",
    "        correct_pred += (y == y_pred).sum().item()\n",
    "    accuracy = correct_pred / len(y_test)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "248805f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|export\n",
    "# Plot the loss and accuracy\n",
    "plt.plot(accuracy_list, label='Accuracy')\n",
    "plt.plot(loss_list, label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a874af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "\n",
    "nbdev.export.nb_export('digit_tensorflow.ipynb', 'digit_tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78056acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
